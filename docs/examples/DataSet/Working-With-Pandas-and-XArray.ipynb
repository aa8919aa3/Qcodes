{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Pandas and XArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how Pandas and XArray can be used to work with the [QCoDeS DataSet](DataSet-class-walkthrough.ipynb). It is not meant as a general introduction to Pandas and XArray. We refer to the official documentation for [Pandas](https://pandas.pydata.org/) and [XArray](http://xarray.pydata.org/en/stable/) for this. This notebook requires that both Pandas and XArray are installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we borrow an example from the measurement notebook to have some data to work with. We split the measurement in two so we can try merging it with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging hadn't been started.\n",
      "Activating auto-logging. Current session state plus future input saved.\n",
      "Filename       : C:\\Users\\a-halakh\\.qcodes\\logs\\command_history.log\n",
      "Mode           : append\n",
      "Output logging : True\n",
      "Raw input log  : False\n",
      "Timestamping   : True\n",
      "State          : active\n",
      "Qcodes Logfile : C:\\Users\\a-halakh\\.qcodes\\logs\\200415-23360-qcodes.log\n",
      "Activating auto-logging. Current session state plus future input saved.\n",
      "Filename       : C:\\Users\\a-halakh\\.qcodes\\logs\\command_history.log\n",
      "Mode           : append\n",
      "Output logging : True\n",
      "Raw input log  : False\n",
      "Timestamping   : True\n",
      "State          : active\n",
      "Qcodes Logfile : C:\\Users\\a-halakh\\.qcodes\\logs\\200415-23360-qcodes.log\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import qcodes as qc\n",
    "from qcodes import load_or_create_experiment, initialise_database, Measurement\n",
    "from qcodes.tests.instrument_mocks import DummyInstrument\n",
    "\n",
    "qc.logger.start_all_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparatory mocking of physical setup\n",
    "dac = DummyInstrument('dac', gates=['ch1', 'ch2'])\n",
    "dmm = DummyInstrument('dmm', gates=['v1', 'v2'])\n",
    "station = qc.Station(dmm, dac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialise_database()\n",
    "exp = load_or_create_experiment(experiment_name='working_with_pandas',\n",
    "                          sample_name=\"no sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qcodes.dataset.measurements.Measurement at 0x242d430b688>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meas = Measurement(exp)\n",
    "meas.register_parameter(dac.ch1)  # register the first independent parameter\n",
    "meas.register_parameter(dac.ch2)  # register the second independent parameter\n",
    "meas.register_parameter(dmm.v1, setpoints=(dac.ch1, dac.ch2))  # register the dependent one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dmm_parameter simulate a physical signal, in this case an exponentially\n",
    "# decaying signal \n",
    "\n",
    "class dmm_gauss_parameter(qc.Parameter):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.gauss = self.gauss_model(0.1, 0.2, 0.25)\n",
    "        next(self.gauss)\n",
    "\n",
    "\n",
    "    def get_raw(self):\n",
    "        \"\"\"\n",
    "        This method is automatically wrapped to\n",
    "        provide a ``get`` method on the parameter instance.\n",
    "        \"\"\"\n",
    "        val = self.gauss.send((dac.ch1.get(), dac.ch2.get()))\n",
    "        next(self.gauss)\n",
    "        return val\n",
    "\n",
    "    def gauss_model(self, x0: float, y0: float, sigma: float, noise: float=0.0005):\n",
    "        \"\"\"\n",
    "        Returns a generator sampling a gaussian. The gaussian is\n",
    "        normalised such that its maximal value is simply 1\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            (x, y) = yield\n",
    "            model = np.exp(-((x0-x)**2+(y0-y)**2)/2/sigma**2)*np.exp(2*sigma**2)\n",
    "            noise = np.random.randn()*noise\n",
    "            yield model + noise\n",
    "\n",
    "    \n",
    "dmm.v1 = dmm_gauss_parameter('dmm_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then perform a very basic experiment. To be able to demonstrate merging of datasets in Pandas we will perform the measurement in two parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experimental run with id: 237. \n"
     ]
    }
   ],
   "source": [
    "# run a 2D sweep\n",
    "\n",
    "with meas.run() as datasaver:\n",
    "\n",
    "    for v1 in np.linspace(-1, 0, 200, endpoint=False):\n",
    "        for v2 in np.linspace(-1, 1, 201):\n",
    "            dac.ch1(v1)\n",
    "            dac.ch2(v2)\n",
    "            val = dmm.v1.get()\n",
    "            datasaver.add_result((dac.ch1, v1),\n",
    "                                 (dac.ch2, v2),\n",
    "                                 (dmm.v1, val))\n",
    "            \n",
    "df1 = datasaver.dataset.get_data_as_pandas_dataframe()['dmm_v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 10:25:37,830 ¦ qcodes.dataset.sqlite.connection ¦ ERROR ¦ connection ¦ atomic ¦ 106 ¦ Rolling back due to unhandled exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\connection.py\", line 103, in atomic\n",
      "    yield conn\n",
      "  File \"c:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\queries.py\", line 1146, in _insert_run\n",
      "    parent_dataset_links)\n",
      "  File \"c:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\connection.py\", line 134, in transaction\n",
      "    c.execute(sql, args)\n",
      "sqlite3.OperationalError: database is locked\n",
      "2020-04-15 10:25:37,840 ¦ qcodes.dataset.sqlite.connection ¦ ERROR ¦ connection ¦ atomic ¦ 106 ¦ Rolling back due to unhandled exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\connection.py\", line 103, in atomic\n",
      "    yield conn\n",
      "  File \"c:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\queries.py\", line 1146, in _insert_run\n",
      "    parent_dataset_links)\n",
      "  File \"c:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\connection.py\", line 134, in transaction\n",
      "    c.execute(sql, args)\n",
      "sqlite3.OperationalError: database is locked\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\connection.py\", line 103, in atomic\n",
      "    yield conn\n",
      "  File \"c:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\queries.py\", line 1541, in create_run\n",
      "    parent_dataset_links)\n",
      "  File \"c:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\queries.py\", line 1146, in _insert_run\n",
      "    parent_dataset_links)\n",
      "  File \"C:\\Users\\a-halakh\\AppData\\Local\\Continuum\\anaconda3\\envs\\qcodes\\lib\\contextlib.py\", line 130, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"c:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\connection.py\", line 107, in atomic\n",
      "    raise RuntimeError(\"Rolling back due to unhandled exception\") from e\n",
      "RuntimeError: Rolling back due to unhandled exception\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Rolling back due to unhandled exception",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\connection.py\u001b[0m in \u001b[0;36matomic\u001b[1;34m(conn)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'BEGIN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\queries.py\u001b[0m in \u001b[0;36m_insert_run\u001b[1;34m(conn, exp_id, name, guid, parameters, captured_run_id, captured_counter, parent_dataset_links)\u001b[0m\n\u001b[0;32m   1145\u001b[0m                                \u001b[0mcaptured_counter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m                                parent_dataset_links)\n\u001b[0m\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\connection.py\u001b[0m in \u001b[0;36mtransaction\u001b[1;34m(conn, sql, *args)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: database is locked",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\connection.py\u001b[0m in \u001b[0;36matomic\u001b[1;34m(conn)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'BEGIN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\queries.py\u001b[0m in \u001b[0;36mcreate_run\u001b[1;34m(conn, exp_id, name, guid, parameters, values, metadata, captured_run_id, captured_counter, parent_dataset_links)\u001b[0m\n\u001b[0;32m   1540\u001b[0m                                                           \u001b[0mcaptured_counter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1541\u001b[1;33m                                                           parent_dataset_links)\n\u001b[0m\u001b[0;32m   1542\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\queries.py\u001b[0m in \u001b[0;36m_insert_run\u001b[1;34m(conn, exp_id, name, guid, parameters, captured_run_id, captured_counter, parent_dataset_links)\u001b[0m\n\u001b[0;32m   1145\u001b[0m                                \u001b[0mcaptured_counter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m                                parent_dataset_links)\n\u001b[0m\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\qcodes\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\connection.py\u001b[0m in \u001b[0;36matomic\u001b[1;34m(conn)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Rolling back due to unhandled exception\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Rolling back due to unhandled exception\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Rolling back due to unhandled exception",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5792f0326235>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# run a 2D sweep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mmeas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdatasaver\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mv1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m201\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\measurements.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m             self.ds = qc.new_data_set(\n\u001b[1;32m--> 626\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m             )\n\u001b[0;32m    628\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\data_set.py\u001b[0m in \u001b[0;36mnew_data_set\u001b[1;34m(name, exp_id, specs, values, metadata, conn)\u001b[0m\n\u001b[0;32m   1383\u001b[0m     d = DataSet(path_to_db=None, run_id=None, conn=conn,\n\u001b[0;32m   1384\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1385\u001b[1;33m                 metadata=metadata, exp_id=exp_id)\n\u001b[0m\u001b[0;32m   1386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\data_set.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_to_db, run_id, conn, exp_id, name, specs, values, metadata)\u001b[0m\n\u001b[0;32m    315\u001b[0m                                        \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                                        \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                                        metadata=metadata)\n\u001b[0m\u001b[0;32m    318\u001b[0m             \u001b[1;31m# this is really the UUID (an ever increasing count in the db)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\queries.py\u001b[0m in \u001b[0;36mcreate_run\u001b[1;34m(conn, exp_id, name, guid, parameters, values, metadata, captured_run_id, captured_counter, parent_dataset_links)\u001b[0m\n\u001b[0;32m   1543\u001b[0m             \u001b[0madd_meta_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1544\u001b[0m         \u001b[0m_update_experiment_run_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_counter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1545\u001b[1;33m         \u001b[0m_create_run_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatted_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrun_counter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatted_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\qcodes\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a-halakh\\documents\\microsoft\\qcodes\\qcodes\\dataset\\sqlite\\connection.py\u001b[0m in \u001b[0;36matomic\u001b[1;34m(conn)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Rolling back due to unhandled exception\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Rolling back due to unhandled exception\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_outmost\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Rolling back due to unhandled exception"
     ]
    }
   ],
   "source": [
    "# run a 2D sweep\n",
    "\n",
    "with meas.run() as datasaver:\n",
    "\n",
    "    for v1 in np.linspace(0, 1, 201):\n",
    "        for v2 in np.linspace(-1, 1, 201):\n",
    "            dac.ch1(v1)\n",
    "            dac.ch2(v2)\n",
    "            val = dmm.v1.get()\n",
    "            datasaver.add_result((dac.ch1, v1),\n",
    "                                 (dac.ch2, v2),\n",
    "                                 (dmm.v1, val))\n",
    "            \n",
    "df2 = datasaver.dataset.get_data_as_pandas_dataframe()['dmm_v1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_data_as_pandas_dataframe` returns the data as a dict from measured (dependent) parameters to DataFrames. Here we are only interested in the dataframe of a single parameter, so we select that from the dict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first inspect the Pandas DataFrame. Note how both dependent variables are used for the index. Pandas refers to this as a [MultiIndex](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html). For visual clarity, we just look at the first N points of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reset the index to return a simpler view where all data points are simply indexed by a running counter. As we shall see below this can be needed in some situations. Note that calling `reset_index` leaves the original dataframe untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.reset_index()[0:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has built-in support for various forms of plotting. This does not, however, support MultiIndex at the moment so we use `reset_index` to make the data available for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.reset_index().plot.scatter('dac_ch1', 'dac_ch2', c='dmm_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for the other dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.reset_index().plot.scatter('dac_ch1', 'dac_ch2', c='dmm_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging two dataframes with the same labels is fairly simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().plot.scatter('dac_ch1', 'dac_ch2', c='dmm_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to select a subset of data from the datframe based on the x and y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(slice(-1, -0.95), slice(-1, -0.97)), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with XArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases when working with data on a rectangular grids it may be more convenient to export the data to a [XArray](http://xarray.pydata.org) Dataset or DataArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas DataSet can be directly converted to a XArray [Dataset](http://xarray.pydata.org/en/stable/data-structures.html?#dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaDataSet = df.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in many cases it is more convenient to work with a XArray [DataArray](http://xarray.pydata.org/en/stable/data-structures.html?#dataarray). The DataArray can only contain a single dependent variable and can be obtained from the Dataset by indexing using the parameter name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaDataArray = xaDataSet['dmm_v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaDataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "xaDataArray.plot(ax=ax[0,0])\n",
    "xaDataArray.mean(dim='dac_ch1').plot(ax=ax[1,0])\n",
    "xaDataArray.mean(dim='dac_ch2').plot(ax=ax[0,1])\n",
    "xaDataArray[200,:].plot(ax=ax[1,1])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we demonstrated a few ways to index the data from a DataArray. For instance the DataArray can be directly plotted, the extracted mean or a specific row/column can also be plotted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
